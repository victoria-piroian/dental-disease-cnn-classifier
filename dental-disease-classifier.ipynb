{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "###Imports"
      ],
      "metadata": {
        "id": "ImAuNEmfH2Bj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torch.utils.data import SubsetRandomSampler, DataLoader, Subset, Dataset\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.datasets as datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from collections import Counter\n",
        "import os\n",
        "from PIL import Image\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "import random\n",
        "from skimage.feature import hog\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import svm\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "slRP23lbHzmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "-TqR4Yg0UtYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "_6AS_DkTJFNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Data Processing"
      ],
      "metadata": {
        "id": "24GxVBmWHnKm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Testing Processing Techniques"
      ],
      "metadata": {
        "id": "rPFbW5E6lG-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "root_dir = \"/content/drive/MyDrive/Fourth Year/APS360/APS360 Project/Data/Raw Images/\"\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),  # Resize all images to 128x128\n",
        "    transforms.ToTensor()           # Converting images to tensors\n",
        "])\n",
        "\n",
        "dataset = datasets.ImageFolder(root=root_dir, transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
        "\n",
        "# Show the number of images in each class\n",
        "class_names = dataset.classes\n",
        "class_counts = Counter(dataset.targets)\n",
        "print(\"Number of images per class:\")\n",
        "for class_name, count in zip(class_names, [class_counts[i] for i in range(len(class_names))]):\n",
        "    print(f\"{class_name}: {count}\")"
      ],
      "metadata": {
        "id": "y7xUyG6kIo4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to visualize images\n",
        "def imshow(imgs, labels, class_names):\n",
        "    imgs = imgs.numpy().transpose((0, 2, 3, 1))  # Convert to (H, W, C)\n",
        "    fig, axes = plt.subplots(1, len(imgs), figsize=(12, 4))\n",
        "    for i, (img, label) in enumerate(zip(imgs, labels)):\n",
        "        axes[i].imshow(np.clip(img, 0, 1))  # Clip to valid range\n",
        "        axes[i].set_title(class_names[label])\n",
        "        axes[i].axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "# Get a batch of images\n",
        "data_iter = iter(dataloader)\n",
        "images, labels = next(data_iter)\n",
        "\n",
        "# Get class names\n",
        "class_names = dataset.classes\n",
        "\n",
        "# Show images before processing\n",
        "imshow(images, labels, class_names)"
      ],
      "metadata": {
        "id": "593AL2R8I6kC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#NOISE REDUCTION\n",
        "def denoise_image(img):\n",
        "    img = (img * 255).astype(np.uint8)  # Convert to uint8 format\n",
        "    img_denoised = cv2.fastNlMeansDenoisingColored(img, None, 10, 10, 7, 21)\n",
        "    return img_denoised.astype(np.float32) / 255.0  # Normalize back to [0, 1] range\n",
        "\n",
        "# Function to show images\n",
        "def imshow(imgs, labels, class_names, denoise=False):\n",
        "    imgs = imgs.numpy().transpose((0, 2, 3, 1))  # Convert to (H, W, C)\n",
        "    if denoise:\n",
        "        imgs = np.array([denoise_image(img) for img in imgs])\n",
        "    fig, axes = plt.subplots(1, len(imgs), figsize=(12, 4))\n",
        "    for i, (img, label) in enumerate(zip(imgs, labels)):\n",
        "        axes[i].imshow(np.clip(img, 0, 1))  # Clip to valid range\n",
        "        axes[i].set_title(class_names[label])\n",
        "        axes[i].axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "# Get a batch of images\n",
        "data_iter = iter(dataloader)\n",
        "images, labels = next(data_iter)\n",
        "\n",
        "# Get class names\n",
        "class_names = dataset.classes\n",
        "\n",
        "# Show original images\n",
        "imshow(images, labels, class_names)\n",
        "\n",
        "# Show denoised images\n",
        "imshow(images, labels, class_names, denoise=True)"
      ],
      "metadata": {
        "id": "ag2a66rA5KFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CONTRAST MAPPING\n",
        "def contrast_map(img):\n",
        "    img = (img * 255).astype(np.uint8)  # Convert to uint8 format\n",
        "    lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)  # Convert to LAB color space\n",
        "    l, a, b = cv2.split(lab)\n",
        "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))  # Apply CLAHE to L channel\n",
        "    l = clahe.apply(l)\n",
        "    lab = cv2.merge((l, a, b))\n",
        "    img_contrast = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)  # Convert back to RGB\n",
        "    return img_contrast.astype(np.float32) / 255.0  # Normalize back to [0, 1] range\n",
        "\n",
        "# Function to show images\n",
        "def imshow(imgs, labels, class_names, contrast=False):\n",
        "    imgs = imgs.numpy().transpose((0, 2, 3, 1))  # Convert to (H, W, C)\n",
        "    if contrast:\n",
        "        imgs = np.array([contrast_map(img) for img in imgs])\n",
        "    fig, axes = plt.subplots(1, len(imgs), figsize=(12, 4))\n",
        "    for i, (img, label) in enumerate(zip(imgs, labels)):\n",
        "        axes[i].imshow(np.clip(img, 0, 1))  # Clip to valid range\n",
        "        axes[i].set_title(class_names[label])\n",
        "        axes[i].axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "# Get a batch of images\n",
        "data_iter = iter(dataloader)\n",
        "images, labels = next(data_iter)\n",
        "\n",
        "# Get class names\n",
        "class_names = dataset.classes\n",
        "\n",
        "# Show original images\n",
        "imshow(images, labels, class_names)\n",
        "\n",
        "# Show contrast-enhanced images\n",
        "imshow(images, labels, class_names, contrast=True)"
      ],
      "metadata": {
        "id": "0gAn7Vaw5K_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#STANDARDIZATION\n",
        "def standardize_image(img):\n",
        "    mean = np.mean(img, axis=(0, 1), keepdims=True)  # Compute mean per channel\n",
        "    std = np.std(img, axis=(0, 1), keepdims=True)  # Compute std per channel\n",
        "    standardized_img = (img - mean) / (std + 1e-8)  # Avoid division by zero\n",
        "    standardized_img = standardized_img * 0.2 + 0.5  # Scale to reduce contrast\n",
        "    return np.clip(standardized_img, 0, 1)  # Clip values to valid range\n",
        "\n",
        "# Function to show images\n",
        "def imshow(imgs, labels, class_names, standardize=False):\n",
        "    imgs = imgs.numpy().transpose((0, 2, 3, 1))  # Convert to (H, W, C)\n",
        "    if standardize:\n",
        "        imgs = np.array([standardize_image(img) for img in imgs])\n",
        "    fig, axes = plt.subplots(1, len(imgs), figsize=(12, 4))\n",
        "    for i, (img, label) in enumerate(zip(imgs, labels)):\n",
        "        axes[i].imshow(np.clip(img, 0, 1))  # Clip to valid range\n",
        "        axes[i].set_title(class_names[label])\n",
        "        axes[i].axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "# Get a batch of images\n",
        "data_iter = iter(dataloader)\n",
        "images, labels = next(data_iter)\n",
        "\n",
        "# Get class names\n",
        "class_names = dataset.classes\n",
        "\n",
        "# Show original images\n",
        "imshow(images, labels, class_names)\n",
        "\n",
        "# Show standardized images\n",
        "imshow(images, labels, class_names, standardize=True)"
      ],
      "metadata": {
        "id": "87DmXsiMbdQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ENHANCE GUM COLOUR\n",
        "def enhance_gum_color(image):\n",
        "    # Convert to numpy if it is a Tensor\n",
        "    if not isinstance(image, np.ndarray):\n",
        "        image = image.numpy().transpose(1, 2, 0)  # CHW to HWC\n",
        "    # Ensure uint8\n",
        "    image = (image * 255).astype(np.uint8) if image.max() <= 1 else image.astype(np.uint8)\n",
        "    # Apply CLAHE to red channel\n",
        "    red_channel = image[:, :, 0]\n",
        "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
        "    red_eq = clahe.apply(red_channel)\n",
        "    image[:, :, 0] = red_eq\n",
        "    # Convert back to float [0,1] for display\n",
        "    image = image.astype(np.float32) / 255.0\n",
        "    return image\n",
        "\n",
        "\n",
        "# Function to show images\n",
        "def imshow(imgs, labels, class_names, enhancegumcolour=False):\n",
        "    imgs = imgs.numpy().transpose((0, 2, 3, 1))  # Convert to (H, W, C)\n",
        "    if enhancegumcolour:\n",
        "        imgs = np.array([enhance_gum_color(img) for img in imgs])\n",
        "    fig, axes = plt.subplots(1, len(imgs), figsize=(12, 4))\n",
        "    for i, (img, label) in enumerate(zip(imgs, labels)):\n",
        "        axes[i].imshow(np.clip(img, 0, 1))  # Clip to valid range\n",
        "        axes[i].set_title(class_names[label])\n",
        "        axes[i].axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "# Get a batch of images\n",
        "data_iter = iter(dataloader)\n",
        "images, labels = next(data_iter)\n",
        "\n",
        "# Get class names\n",
        "class_names = dataset.classes\n",
        "\n",
        "# Show original images\n",
        "imshow(images, labels, class_names)\n",
        "\n",
        "# Show standardized images\n",
        "imshow(images, labels, class_names, enhancegumcolour=True)"
      ],
      "metadata": {
        "id": "w_CThQ203QCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Applying Processing Techniques"
      ],
      "metadata": {
        "id": "1t5I0fAwlPLJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "root_dir = \"/content/drive/MyDrive/Fourth Year/APS360/APS360 Project/Data/Raw Images/\"\n",
        "\n",
        "# Define transform pipeline\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),  # Resize all images\n",
        "    transforms.ToTensor(),  # Convert to tensor\n",
        "    transforms.Lambda(lambda img: img.permute(1, 2, 0).numpy()),  # Convert (C, H, W) to (H, W, C)\n",
        "    transforms.Lambda(lambda img: denoise_image(img)),            # Apply denoising\n",
        "    transforms.Lambda(lambda img: contrast_map(img)),             # Apply contrast mapping\n",
        "    transforms.Lambda(lambda img: enhance_gum_color(img)),        # Enhance red channel\n",
        "    transforms.Lambda(lambda img: standardize_image(img)),        # Apply standardization\n",
        "    transforms.Lambda(lambda img: torch.tensor(img).permute(2, 0, 1))  # Convert back to (C, H, W) tensor\n",
        "])\n",
        "\n",
        "# Load dataset with preprocessing\n",
        "dataset = datasets.ImageFolder(root=root_dir, transform=transform)\n"
      ],
      "metadata": {
        "id": "BzUqv3V2DhD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Proportional Stratified Sampling Without Replacement"
      ],
      "metadata": {
        "id": "Z3BiBUC6l_H7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract labels for stratified splitting\n",
        "labels = np.array(dataset.targets)\n",
        "\n",
        "# Stratified split\n",
        "train_idx, temp_idx, train_labels, temp_labels = train_test_split(\n",
        "    np.arange(len(dataset)), labels, stratify=labels, test_size=0.30, random_state=42\n",
        ")\n",
        "val_idx, test_idx = train_test_split(\n",
        "    temp_idx, stratify=temp_labels, test_size=0.50, random_state=42\n",
        ")\n",
        "\n",
        "# Create dataset subsets\n",
        "train_dataset = Subset(dataset, train_idx)\n",
        "val_dataset = Subset(dataset, val_idx)\n",
        "test_dataset = Subset(dataset, test_idx)"
      ],
      "metadata": {
        "id": "6KkK7vw0l9bn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Augmentation (Training Dataset)"
      ],
      "metadata": {
        "id": "lX3nWI2DlUfE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BALANCING Augmentations\n",
        "augmentation_transforms = transforms.Compose([\n",
        "    transforms.RandomRotation(25),  # Rotate image randomly up to 25 degrees\n",
        "    transforms.RandomHorizontalFlip(p=0.5),  # Flip image horizontally\n",
        "    transforms.RandomResizedCrop(128, scale=(0.8, 1.0)),  # Random crop\n",
        "    transforms.RandomApply([transforms.GaussianBlur(kernel_size=(5, 5))], p=0.3),  # Blur with 30% probability\n",
        "    transforms.RandomApply([transforms.Lambda(lambda x: x + 0.05 * torch.randn_like(x))], p=0.3),  # Add noise with 30% probability\n",
        "    transforms.RandomApply([transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)], p=0.3)  # Color jitter with 30% probability\n",
        "])\n",
        "\n",
        "class BalancedDataset(Dataset):\n",
        "    def __init__(self, dataset, full_dataset, augmentation_transforms):\n",
        "        self.dataset = dataset\n",
        "        self.full_dataset = full_dataset\n",
        "        self.augmentation_transforms = augmentation_transforms\n",
        "        # Extract labels from the subset dataset\n",
        "        self.targets = np.array([full_dataset.targets[i] for i in dataset.indices])\n",
        "        # Compute class distribution in the training subset\n",
        "        self.class_counts = Counter(self.targets)\n",
        "        # Find the largest class count to balance all classes\n",
        "        self.max_samples = max(self.class_counts.values())\n",
        "        # Get indices of images for each class\n",
        "        self.indices_per_class = self.get_class_indices()\n",
        "        # Generate a list of indices that creates a balanced dataset\n",
        "        self.balanced_indices = self.generate_balanced_indices()\n",
        "\n",
        "    def get_class_indices(self):\n",
        "        class_indices = {}\n",
        "        for cls in self.class_counts.keys():\n",
        "            class_indices[cls] = []\n",
        "        for idx, label in zip(self.dataset.indices, self.targets):\n",
        "            class_indices[label].append(idx)\n",
        "        return class_indices\n",
        "\n",
        "    def generate_balanced_indices(self):\n",
        "        balanced_indices = []\n",
        "        for cls, indices in self.indices_per_class.items():\n",
        "            num_samples = len(indices)\n",
        "            num_to_add = self.max_samples - num_samples\n",
        "            # Keep original indices\n",
        "            new_class_indices = indices.copy()\n",
        "            # Add extra augmented samples if necessary\n",
        "            if num_to_add > 0:\n",
        "                extra_indices = random.choices(indices, k=num_to_add)\n",
        "                new_class_indices.extend(extra_indices)\n",
        "            # Add to final dataset\n",
        "            balanced_indices.extend(new_class_indices)\n",
        "        return balanced_indices\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.balanced_indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        original_idx = self.balanced_indices[idx]\n",
        "        img, label = self.full_dataset[original_idx]\n",
        "        # Apply augmentation only to oversampled images\n",
        "        if self.balanced_indices.count(original_idx) > 1:\n",
        "            img = self.augmentation_transforms(img)\n",
        "        return img, label\n",
        "\n",
        "balanced_train_dataset = BalancedDataset(train_dataset, dataset, augmentation_transforms)"
      ],
      "metadata": {
        "id": "SK8vNaKEpf1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Check Class Distribution"
      ],
      "metadata": {
        "id": "ZYh_otn_uLkz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dataset_class_distribution(subset, name):\n",
        "    # Get the mapping from index to class\n",
        "    idx_to_class = {v: k for k, v in subset.dataset.class_to_idx.items()}\n",
        "\n",
        "    # Access the labels using subset.indices\n",
        "    subset_labels = [subset.dataset.targets[i] for i in subset.indices]\n",
        "\n",
        "    # Count the occurrences of each label\n",
        "    label_counts = Counter(subset_labels)\n",
        "\n",
        "    # Print label distribution\n",
        "    print(f\"\\n{name} label distribution:\")\n",
        "    for label, count in sorted(label_counts.items()):\n",
        "        class_name = idx_to_class[label]\n",
        "        print(f\"{class_name}: {count}\")\n",
        "\n",
        "    print(f\"Total samples: {sum(label_counts.values())}\")\n",
        "\n",
        "dataset_class_distribution(train_dataset, \"Train Dataset\")\n",
        "dataset_class_distribution(val_dataset, \"Validation Dataset\")\n",
        "dataset_class_distribution(test_dataset, \"Test Dataset\")\n",
        "\n",
        "print(f\"\\nLength of balanced_train_dataset: {len(balanced_train_dataset)}\")"
      ],
      "metadata": {
        "id": "GJDe_fbJr3D3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_balanced_indices_distribution(balanced_dataset):\n",
        "    labels = [balanced_dataset.full_dataset.targets[i] for i in balanced_dataset.balanced_indices]\n",
        "    label_counts = Counter(labels)\n",
        "    print(\"\\nBalanced Dataset Distribution:\")\n",
        "    for label, count in sorted(label_counts.items()):\n",
        "        print(f\"Class {label}: {count}\")\n",
        "    print(f\"Total samples: {sum(label_counts.values())}\")\n",
        "\n",
        "\n",
        "check_balanced_indices_distribution(balanced_train_dataset)"
      ],
      "metadata": {
        "id": "TYmxUlvEA61P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Baseline Model"
      ],
      "metadata": {
        "id": "jDUt2fqul67M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader64 = DataLoader(balanced_train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader64 = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "test_loader64 = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "jbUlakV8kseu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract HOG features from a dataset\n",
        "def extract_hog_features(data_loader):\n",
        "    hog_features = []\n",
        "    labels = []\n",
        "\n",
        "    for images, targets in data_loader:\n",
        "        for i in range(images.size(0)):\n",
        "            # Convert tensor to numpy array and to grayscale\n",
        "            image = images[i].numpy().transpose(1, 2, 0)\n",
        "            gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "            # Extract HOG features\n",
        "            features, _ = hog(gray_image, orientations=9, pixels_per_cell=(8, 8),\n",
        "                              cells_per_block=(2, 2), block_norm='L2-Hys', visualize=True)\n",
        "            hog_features.append(features)\n",
        "            labels.append(targets[i].item())\n",
        "\n",
        "    return np.array(hog_features), np.array(labels)\n",
        "\n",
        "# Extract features from each dataset\n",
        "X_train, y_train = extract_hog_features(train_loader64)\n",
        "X_test, y_test = extract_hog_features(test_loader64)\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Hyperparameter tuning with GridSearchCV\n",
        "param_grid = {'C': [1, 10], 'kernel': ['rbf', 'poly'], 'gamma': ['scale', 'auto']}\n",
        "model = GridSearchCV(svm.SVC(), param_grid, cv=3)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best parameters: {model.best_params_}\")\n",
        "\n",
        "\n",
        "# Evaluate model on test set\n",
        "test_predictions = model.predict(X_test)\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, test_predictions))\n",
        "print(\"Test Classification Report:\\n\", classification_report(y_test, test_predictions))\n",
        "\n",
        "# Confusion matrix for test set\n",
        "cm = confusion_matrix(y_test, test_predictions)\n",
        "ConfusionMatrixDisplay(cm).plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "E5AjbigCmB7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Primary Model"
      ],
      "metadata": {
        "id": "PxURa2wrHvE1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_net(model, model_name, learning_rate, num_epochs, train_loader, val_loader, criterion, optimizer):\n",
        "    # Fixed PyTorch random seed for reproducible result\n",
        "    torch.manual_seed(1000)\n",
        "    model.to(device)\n",
        "\n",
        "    # Set up numpy arrays to store the training/test loss/err\n",
        "    train_err = np.zeros(num_epochs)\n",
        "    train_loss = np.zeros(num_epochs)\n",
        "    val_err = np.zeros(num_epochs)\n",
        "    val_loss = np.zeros(num_epochs)\n",
        "\n",
        "    # Train the network\n",
        "    start_time = time.time()\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_train_loss = 0.0\n",
        "        total_train_err = 0.0\n",
        "        total_epoch = 0\n",
        "        for i, (inputs, labels) in enumerate(train_loader, 0):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            corr = preds != labels\n",
        "            total_train_err += corr.sum().item()\n",
        "            total_train_loss += loss.item()\n",
        "            total_epoch += len(labels)\n",
        "\n",
        "        train_err[epoch] = float(total_train_err) / total_epoch\n",
        "        train_loss[epoch] = float(total_train_loss) / (i+1)\n",
        "\n",
        "        model.eval()\n",
        "        total_val_loss = 0.0\n",
        "        total_val_err = 0.0\n",
        "        total_epoch = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                preds = outputs.argmax(dim=1)\n",
        "                corr = preds != labels\n",
        "                total_val_err += corr.sum().item()\n",
        "                total_val_loss += loss.item()\n",
        "                total_epoch += len(labels)\n",
        "\n",
        "        val_err[epoch] = float(total_val_err) / total_epoch\n",
        "        val_loss[epoch] = float(total_val_loss) / len(val_loader)\n",
        "\n",
        "        print((\"Epoch {}: Train err: {}, Train loss: {} |\"+\n",
        "               \"Validation err: {}, Validation loss: {}\").format(\n",
        "                   epoch + 1,\n",
        "                   train_err[epoch],\n",
        "                   train_loss[epoch],\n",
        "                   val_err[epoch],\n",
        "                   val_loss[epoch]))\n",
        "    print('Finished Training')\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "    print(\"Total time elapsed: {:.2f} seconds\".format(elapsed_time))\n",
        "\n",
        "    # Write the train/test loss/err into CSV file for plotting\n",
        "    np.savetxt(\"{}_train_err.csv\".format(model_name), train_err)\n",
        "    np.savetxt(\"{}_train_loss.csv\".format(model_name), train_loss)\n",
        "    np.savetxt(\"{}_val_err.csv\".format(model_name), val_err)\n",
        "    np.savetxt(\"{}_val_loss.csv\".format(model_name), val_loss)\n",
        "\n",
        "    train_err = np.loadtxt(\"{}_train_err.csv\".format(model_name))\n",
        "    val_err = np.loadtxt(\"{}_val_err.csv\".format(model_name))\n",
        "    train_loss = np.loadtxt(\"{}_train_loss.csv\".format(model_name))\n",
        "    val_loss = np.loadtxt(\"{}_val_loss.csv\".format(model_name))\n",
        "    plt.title(\"Train vs Validation Error\")\n",
        "    n = len(train_err)\n",
        "    plt.plot(range(1,n+1), train_err, label=\"Train\")\n",
        "    plt.plot(range(1,n+1), val_err, label=\"Validation\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Error\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    plt.title(\"Train vs Validation Loss\")\n",
        "    plt.plot(range(1,n+1), train_loss, label=\"Train\")\n",
        "    plt.plot(range(1,n+1), val_loss, label=\"Validation\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "OE04fZMuU4kc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_net(model, test_loader, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    total_err = 0\n",
        "    total_samples = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            total_err += (preds != labels).sum().item()\n",
        "            total_samples += len(labels)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    test_err = total_err / total_samples\n",
        "    test_loss = total_loss / len(test_loader)\n",
        "\n",
        "    print(f\"Test Err: {test_err:.4f}, Test Loss: {test_loss:.4f}\")\n",
        "\n",
        "    # Print the classification report\n",
        "    print(\"Test Classification Report:\\n\")\n",
        "    print(classification_report(all_labels, all_preds))\n",
        "\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.xlabel(\"Predicted Label\")\n",
        "    plt.ylabel(\"True Label\")\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.show()\n",
        "\n",
        "    cm_normalized = cm.astype('float') / cm.sum(axis=1, keepdims=True)  # Normalize row-wise\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm_normalized, annot=True, fmt=\".2f\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.xlabel(\"Predicted Label\")\n",
        "    plt.ylabel(\"True Label\")\n",
        "    plt.title(\"Confusion Matrix (Proportions)\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "tKjBsIBUVj8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DentalDiagnosisCNN(nn.Module):\n",
        "    def __init__(self, num_classes=6):\n",
        "        super(DentalDiagnosisCNN, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.conv4 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.fc1 = nn.Linear(128 * 8 * 8, 256)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(256, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = F.relu(self.bn1(self.conv1(x)))\n",
        "        x1 = self.pool(x1)\n",
        "\n",
        "        x2 = F.relu(self.bn2(self.conv2(x1)))\n",
        "        x2 = self.pool(x2)\n",
        "\n",
        "        x3 = F.relu(self.bn3(self.conv3(x2)))\n",
        "        x3 = self.pool(x3)\n",
        "\n",
        "        x4 = F.relu(self.bn4(self.conv4(x3)))\n",
        "        x4 = self.pool(x4)\n",
        "\n",
        "        x = torch.flatten(x4, start_dim=1)\n",
        "        x = self.dropout(F.relu(self.fc1(x)))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "D0FiXUwaUvjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = DentalDiagnosisCNN(num_classes=6)\n",
        "learning_rate = 0.001\n",
        "num_epochs = 10\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "train_loader = DataLoader(balanced_train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "train_net(model, 'DentalDiagnosisCNN', learning_rate, num_epochs, train_loader, val_loader, criterion, optimizer)"
      ],
      "metadata": {
        "id": "33zcbVGZULJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_net(model, test_loader, criterion)"
      ],
      "metadata": {
        "id": "8tWMx5rTUltS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Architecture Changes"
      ],
      "metadata": {
        "id": "rIrPrupg8G-a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Version 2.0 (Deeper)"
      ],
      "metadata": {
        "id": "g3a_q5VV_tbV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DentalDiagnosisCNN_2(nn.Module):\n",
        "    def __init__(self, num_classes=6):\n",
        "        super(DentalDiagnosisCNN_2, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.conv4 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.conv5 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn5 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.fc1 = nn.Linear(256 * 4 * 4, 256)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(256, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = F.relu(self.bn1(self.conv1(x)))\n",
        "        x1 = self.pool(x1)\n",
        "\n",
        "        x2 = F.relu(self.bn2(self.conv2(x1)))\n",
        "        x2 = self.pool(x2)\n",
        "\n",
        "        x3 = F.relu(self.bn3(self.conv3(x2)))\n",
        "        x3 = self.pool(x3)\n",
        "\n",
        "        x4 = F.relu(self.bn4(self.conv4(x3)))\n",
        "        x4 = self.pool(x4)\n",
        "\n",
        "        x5 = F.relu(self.bn5(self.conv5(x4)))\n",
        "        x5 = self.pool(x5)\n",
        "\n",
        "        x = torch.flatten(x5, start_dim=1)\n",
        "        x = self.dropout(F.relu(self.fc1(x)))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "zBHro0og8mHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = DentalDiagnosisCNN_2(num_classes=6)\n",
        "learning_rate = 0.001\n",
        "num_epochs = 10\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "train_loader = DataLoader(balanced_train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "train_net(model2, 'DentalDiagnosisCNN_2', learning_rate, num_epochs, train_loader, val_loader, criterion, optimizer)"
      ],
      "metadata": {
        "id": "iSfZwX4Y_7hE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_net(model2, test_loader, criterion)"
      ],
      "metadata": {
        "id": "iH5cz5ggT4pc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Version 3.0 (VGG)"
      ],
      "metadata": {
        "id": "Q6mK7LcUE4Su"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DentalDiagnosisCNN_3(nn.Module):\n",
        "    def __init__(self, num_classes=6):\n",
        "        super(DentalDiagnosisCNN_3, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 3, padding=1), nn.ReLU(),\n",
        "            nn.Conv2d(32, 32, 3, padding=1), nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, 3, padding=1), nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(),\n",
        "            nn.Conv2d(128, 128, 3, padding=1), nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Dropout(0.3)\n",
        "        )\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(128, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "lPGUrJF9E8O9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = DentalDiagnosisCNN_3(num_classes=6)\n",
        "learning_rate = 0.001\n",
        "num_epochs = 10\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "train_loader = DataLoader(balanced_train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "train_net(model3, 'DentalDiagnosisCNN_3', learning_rate, num_epochs, train_loader, val_loader, criterion, optimizer)"
      ],
      "metadata": {
        "id": "-BmjHEOsFE7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_net(model3, test_loader, criterion)"
      ],
      "metadata": {
        "id": "Wub782eYT-FF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Version 4.0 (Lightweight and Fast)"
      ],
      "metadata": {
        "id": "clDqGllbFaMP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DentalDiagnosisCNN_4(nn.Module):\n",
        "    def __init__(self, num_classes=6):\n",
        "        super(DentalDiagnosisCNN_4, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(32, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Dropout(0.3)\n",
        "        )\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(64, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(64, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "6DecNud1FfDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model4 = DentalDiagnosisCNN_4(num_classes=6)\n",
        "learning_rate = 0.001\n",
        "num_epochs = 10\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "train_loader = DataLoader(balanced_train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "train_net(model4, 'DentalDiagnosisCNN_4', learning_rate, num_epochs, train_loader, val_loader, criterion, optimizer)"
      ],
      "metadata": {
        "id": "ZkDqRUssF8dU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_net(model4, test_loader, criterion)"
      ],
      "metadata": {
        "id": "iyg8Cq5PUBD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Version 5.0 (Wide but Shallow)"
      ],
      "metadata": {
        "id": "TaY_ig2-GGh_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DentalDiagnosisCNN_5(nn.Module):\n",
        "    def __init__(self, num_classes=6):\n",
        "        super(DentalDiagnosisCNN_5, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Conv2d(64, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            nn.Dropout(0.4)\n",
        "        )\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(128, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "sWrkAAs-GO5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model5 = DentalDiagnosisCNN_5(num_classes=6)\n",
        "learning_rate = 0.001\n",
        "num_epochs = 10\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "train_loader = DataLoader(balanced_train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "train_net(model5, 'DentalDiagnosisCNN_5', learning_rate, num_epochs, train_loader, val_loader, criterion, optimizer)"
      ],
      "metadata": {
        "id": "q6D6DFzNGhwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_net(model5, test_loader, criterion)"
      ],
      "metadata": {
        "id": "a8EjAtKSUDxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. Hyperparameter Tuning on Version 2.0"
      ],
      "metadata": {
        "id": "59A-Ll6GQ3Y-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hyperparams_list = [\n",
        "    {\"learning_rate\": 0.0005, \"num_epochs\": 20, \"batch_size\": 64, \"optimizer\": \"Adam\"},\n",
        "    {\"learning_rate\": 0.001,  \"num_epochs\": 15, \"batch_size\": 64, \"optimizer\": \"Adam\"},\n",
        "    {\"learning_rate\": 0.0008, \"num_epochs\": 15, \"batch_size\": 32, \"optimizer\": \"Adam\"},\n",
        "    {\"learning_rate\": 0.0005, \"num_epochs\": 20, \"batch_size\": 128, \"optimizer\": \"Adam\"},\n",
        "    {\"learning_rate\": 0.001,  \"num_epochs\": 10, \"batch_size\": 32, \"optimizer\": \"Adam\"},\n",
        "    {\"learning_rate\": 0.001,  \"num_epochs\": 15, \"batch_size\": 64, \"optimizer\": \"SGD\", \"momentum\": 0.9},\n",
        "    {\"learning_rate\": 0.0005, \"num_epochs\": 20, \"batch_size\": 64, \"optimizer\": \"SGD\", \"momentum\": 0.9},\n",
        "    {\"learning_rate\": 0.0005, \"num_epochs\": 20, \"batch_size\": 64, \"optimizer\": \"RMSprop\"},\n",
        "    {\"learning_rate\": 0.0003, \"num_epochs\": 25, \"batch_size\": 128, \"optimizer\": \"Adam\"},\n",
        "]\n",
        "\n",
        "\n",
        "for i, params in enumerate(hyperparams_list):\n",
        "    print(f\"Training model with config {i+1}: {params}\")\n",
        "    train_loader = DataLoader(balanced_train_dataset, batch_size=params[\"batch_size\"], shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=params[\"batch_size\"], shuffle=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=params[\"batch_size\"], shuffle=False)\n",
        "\n",
        "    model = DentalDiagnosisCNN_2(num_classes=6).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    if params[\"optimizer\"] == \"Adam\":\n",
        "        optimizer = optim.Adam(model.parameters(), lr=params[\"learning_rate\"])\n",
        "    elif params[\"optimizer\"] == \"SGD\":\n",
        "        optimizer = optim.SGD(model.parameters(), lr=params[\"learning_rate\"], momentum=0.9)\n",
        "    elif params[\"optimizer\"] == \"RMSprop\":\n",
        "        optimizer = optim.RMSprop(model.parameters(), lr=params[\"learning_rate\"])\n",
        "\n",
        "    train_net(model, f\"model_config_{i+1}\", learning_rate=params[\"learning_rate\"], num_epochs=params[\"num_epochs\"], train_loader=train_loader, val_loader=val_loader, criterion=criterion, optimizer=optimizer)\n",
        "\n",
        "    print(f\"Testing model with config {i+1}\")\n",
        "    test_net(model, test_loader, criterion)\n"
      ],
      "metadata": {
        "id": "ApiGCXLZRoU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6. Test on Unseen Data"
      ],
      "metadata": {
        "id": "ehyw-kB2ISS9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "root_dir_unseen = \"/content/drive/MyDrive/Fourth Year/APS360/APS360 Project/Unseen Test Data/Raw Images/\"\n",
        "unseen_dataset = datasets.ImageFolder(root=root_dir_unseen, transform=transform)\n",
        "unseen_test_loader = DataLoader(unseen_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "V-VPd_TzIjf6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_net(model, unseen_test_loader, criterion)"
      ],
      "metadata": {
        "id": "4Q2JuhdvIZYU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}